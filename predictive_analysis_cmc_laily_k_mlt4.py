# -*- coding: utf-8 -*-
"""Predictive_Analysis_CMC_Laily_K_MLT4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_DcHAuQo9GWHdPmQRZRyMstNtrdvvbLb

# **Laporan Proyek Machine Learning Terapan - Submission 1 _Predictive Analytics_**-
## Klasifikasi Metode Kontrasepsi
Laily Khoirunnisa' - MLT4

##**1. Import library**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import zipfile, os
from google.colab import files
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from sklearn.neighbors import KNeighborsClassifier

!pip install -q kaggle
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!ls ~/.kaggle
!chmod 600 /root/.kaggle/kaggle.json

""" ## **2. Data Loading**"""

!kaggle datasets download -d faizunnabi/contraceptive-method-choice

# melakukan ekstraksi pada file zip
local_zip = 'contraceptive-method-choice.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

"""## **3. Exploratory Data Analysis (EDA)**"""

df = pd.read_csv('/tmp/cmc.data.txt', names=['Usia Istri','Pend. Istri','Pend. Suami','Jumlah Anak', 'Agama Istri','Istri Bekerja','Pekerjaan Suami','Indeks Standar Hidup','Tekanan Media','Metode Kontrasepsi'])
df

df.describe()

df.info()

"""**Menangani Missing Value (True=Ada Missing Value, False=Tidak ada Missing Value)**"""

print("Value kosong pada data :",df.isnull().values.any())

"""**Menghapus duplikat data**"""

df.drop_duplicates(inplace=True)

df.shape

"""**Memeriksa Outlier Fitur Numerik**"""

sns.boxplot(x=df['Usia Istri'])

sns.boxplot(x=df['Jumlah Anak'])

"""Pengeluaran data outliers atau penggunaan data outliers tidak semata-mata merujuk kepada statistiknya, tetapi juga adjustment dari peneliti. Jika memang data outliers tersebut tidak dapat dikeluarkan karena masih merupakan fenomena subjek penelitian ya sebaiknya tetap dipergunakan. _(2015. Data Outliers. konsultasistatstik.com)_

Pada data numerik fitur `Jumlah Anak`, data outlier tidak terlalu banyak. Data yang muncul merupakan fenomena data yang wajar dan dapat terjadi pada keluarga tanpa kontrasepsi.

**Mengatur tipe data kategorikal**
"""

data_types_dict = {'Pend. Istri': str,'Pend. Suami': str,'Agama Istri': str,'Istri Bekerja': str,'Pekerjaan Suami': str,'Indeks Standar Hidup': str,'Tekanan Media': str,'Metode Kontrasepsi': str}
df = df.astype(data_types_dict)
df.dtypes

num_features = ['Usia Istri', 'Jumlah Anak']
cat_features = ['Pend. Istri', 'Pend. Suami', 'Agama Istri', 'Istri Bekerja','Pekerjaan Suami','Indeks Standar Hidup','Tekanan Media','Metode Kontrasepsi']

feature = cat_features[0]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_Pend_Istri = pd.DataFrame({'jumlah sampel':count,'persentase':percent.round(1)})
print(df_Pend_Istri)
count.plot(kind='bar', title=feature);

#Cat_feature : Pend. Suami
feature = cat_features[1]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_Pend_Suami = pd.DataFrame({'jumlah sampel':count,'persentase':percent.round(1)})
print(df_Pend_Suami)
count.plot(kind='bar', title=feature);

#Cat_feature : Agama Istri
feature = cat_features[2]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_Agama = pd.DataFrame({'jumlah sampel':count,'persentase':percent.round(1)})
print(df_Agama)
count.plot(kind='bar', title=feature);

#Cat_feature : Istri Bekerja
feature = cat_features[3]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_bekerja = pd.DataFrame({'jumlah sampel':count,'persentase':percent.round(1)})
print(df_bekerja)
count.plot(kind='bar', title=feature);

#Cat_feature : Pekerjaan Suami
feature = cat_features[4]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_Pek_Suami = pd.DataFrame({'jumlah sampel':count,'persentase':percent.round(1)})
print(df_Pek_Suami)
count.plot(kind='bar', title=feature);

#Cat_feature : Indeks Standar Hidup
feature = cat_features[5]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_ish = pd.DataFrame({'jumlah sampel':count,'persentase':percent.round(1)})
print(df_ish)
count.plot(kind='bar', title=feature);

#Cat_feature : Tekanan Media
feature = cat_features[6]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_media = pd.DataFrame({'jumlah sampel':count,'persentase':percent.round(1)})
print(df_media)
count.plot(kind='bar', title=feature);

#Cat_feature : Metode Kontrasepsi
feature = cat_features[7]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_metode = pd.DataFrame({'jumlah sampel':count,'persentase':percent.round(1)})
print(df_metode)
count.plot(kind='bar', title=feature);

#Num_feature : Usia Istri
sns.countplot(x='Metode Kontrasepsi',data=df,hue="Usia Istri")
#place legend outside bottom right corner of plot
plt.legend(bbox_to_anchor=(1.00, -0.5), loc='lower left', borderaxespad=0).set(title="Jumlah Usia Istri")

sns.countplot(x='Metode Kontrasepsi',data=df,hue="Jumlah Anak")
#place legend outside bottom right corner of plot
plt.legend(bbox_to_anchor=(1.01, 0.005), loc='lower left', borderaxespad=0).set(title="Jumlah Anak")

"""## **4. Exploratory Data Analysis - Multivariate Analysis**"""

cat_features = df.select_dtypes(include='object')
cat_features = list(cat_features.columns)
cat_features_array = np.array(cat_features)
cat_features_array = np.reshape(cat_features_array, (4,2))

rows = 4 ; columns = 2
f, axes = plt.subplots(rows, columns, figsize=(15,15))
print ("Bar Charts for all Categorical Variables")
for row in range(rows):
    for column in range(columns):
      sns.countplot(x='Metode Kontrasepsi',data=df,hue=cat_features_array[row][column],ax=axes[row,column])

"""**Melihat korelasi matriks semua fitur**"""

data_types_dict = {'Pend. Istri': int,'Pend. Suami': int,'Agama Istri': int,'Istri Bekerja': int,'Pekerjaan Suami': int,'Indeks Standar Hidup': int,'Tekanan Media': int,'Metode Kontrasepsi': int}
df = df.astype(data_types_dict)
df.dtypes

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix Semua Fitur ", size=20)

"""**Mengamati hubungan dalam bentuk fitur numerik**"""

sns.pairplot(df, diag_kind = 'kde')

"""## **5. Data Preparation**

**Encoding fitur kategori** --> data sudah dalam bentuk numerik integer

**Reduksi fitur dari korelasi terendah** --> `Agama Istri` dan `Pekerjaan Suami`
"""

df = df.drop(["Agama Istri"],axis =1)

df = df.drop(["Pekerjaan Suami"],axis =1)

df.head()

"""**Pembagian dataset**
Data yang akan diresampling SMOTE dan Tomek Links adalah data training.
"""

X = df.drop(["Metode Kontrasepsi"],axis =1)
y = df["Metode Kontrasepsi"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 20)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""**Penerapan Standarisasi**"""

scaler = StandardScaler()
scaler.fit(X_train[num_features])
X_train[num_features] = scaler.transform(X_train.loc[:, num_features])
X_test[num_features] = scaler.transform(X_test.loc[:, num_features])
X_train[num_features].head()

X_train[num_features].describe().round(4)

"""### **Implementasi Smote, Tomek Link, dan Pipeline pada Model Decision Tree, Random Forest dan Ada Boost**

"""

from imblearn.combine import SMOTETomek
from imblearn.pipeline import make_pipeline
from imblearn.under_sampling import TomekLinks
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn import metrics
from sklearn.model_selection import GridSearchCV

dt = DecisionTreeClassifier(criterion='gini', max_depth=6,splitter='best')

SMOTETomek_pipeline = make_pipeline(SMOTETomek(tomek=TomekLinks(sampling_strategy='majority')), dt)
SMOTETomek_dt = SMOTETomek_pipeline
SMOTETomek_dt.fit(X_train, y_train)

y_pred_dt = SMOTETomek_dt.predict(X_test)
print(classification_report(y_test,y_pred_dt))

#ROC AUC
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_dt, pos_label=3)
metrics.auc(fpr, tpr)

kf = StratifiedKFold(n_splits=5, shuffle=False)
params = {
    'criterion': ['gini'],
    'max_depth': [2, 6, 10, 12, 15],
    'splitter': ['best']
}

grid_dt = GridSearchCV(dt, param_grid=params, cv=kf).fit(X_train, y_train)

grid_dt.best_params_

grid_dt_predictions = grid_dt.predict(X_test)
print(classification_report(y_test,grid_dt_predictions))

#ROC AUC
fpr, tpr, thresholds = metrics.roc_curve(y_test, grid_dt_predictions, pos_label=3)
metrics.auc(fpr, tpr)

rf = RandomForestClassifier(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
SMOTETomek_pipeline = make_pipeline(SMOTETomek(tomek=TomekLinks(sampling_strategy='majority')), rf)
SMOTETomek_rf = SMOTETomek_pipeline
SMOTETomek_rf.fit(X_train, y_train)

y_pred = SMOTETomek_rf.predict(X_test)

print(classification_report(y_test,y_pred))

#ROC AUC
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=3)
metrics.auc(fpr, tpr)

params = {
    'n_estimators': [50, 100, 200],
    'max_depth': [4, 6, 10, 12],
    'random_state': [13,30,50,55,100]
}

grid_rf = GridSearchCV(rf, param_grid=params, cv=kf).fit(X_train, y_train)

grid_rf.best_params_

grid_rf_predictions = grid_rf.predict(X_test)
print(classification_report(y_test,grid_rf_predictions))

#ROC AUC
fpr, tpr, thresholds = metrics.roc_curve(y_test,grid_rf_predictions, pos_label=3)
metrics.auc(fpr, tpr)

from sklearn.ensemble import AdaBoostClassifier

ab = AdaBoostClassifier(learning_rate=0.05, random_state=50)
SMOTETomek_pipeline = make_pipeline(SMOTETomek(tomek=TomekLinks(sampling_strategy='majority')), ab)
SMOTETomek_AB = SMOTETomek_pipeline
SMOTETomek_AB.fit(X_train, y_train)

y_pred_AB = SMOTETomek_AB.predict(X_test)
print(classification_report(y_test,y_pred_AB))

#ROC AUC
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_AB, pos_label=3)
metrics.auc(fpr, tpr)

params_ab = {
    'learning_rate': [0.01, 0.02, 0.03, 0.05, 0.1],
    'random_state': [5,10,13,15,20,30,50]
}

grid_ab = GridSearchCV(ab, param_grid=params_ab, cv=kf).fit(X_train, y_train)

grid_ab.best_params_

grid_ab_predictions = grid_ab.predict(X_test)
print(classification_report(y_test,grid_ab_predictions))

#ROC AUC
fpr, tpr, thresholds = metrics.roc_curve(y_test, grid_ab_predictions, pos_label=3)
metrics.auc(fpr, tpr)